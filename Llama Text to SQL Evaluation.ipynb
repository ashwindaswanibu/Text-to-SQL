{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d_VF6Mnrx7Bh",
    "outputId": "a4acbee1-b7fa-4da3-edb4-35d98740908f"
   },
   "outputs": [],
   "source": [
    "!pip install openai==0.28 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1HnQ6fZTKTm1"
   },
   "outputs": [],
   "source": [
    "api_key = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131,
     "referenced_widgets": [
      "c7ff01223950457f8286c36374a89cd2",
      "f6118099e4914a978c79ec9f6755d372",
      "0edebfbe8f204097ab9dd6e2d311bc16",
      "3918ba3379414eb3a90ffd0c017d44b5",
      "bf2e8347ab534e4c8194f8ccf55ec6a2",
      "691f9668a10e4f3883f56f37f54e3a0b",
      "000d51fc5c404daba188f58c86ce72a0",
      "4362d479c3044e7a9e496e03ac1bc9a5",
      "2f9a4afa9c9d479a93b06cff6eda09c6",
      "d3a47070203a4079a6e0100a391f6df0",
      "e20f1a733c4e468cbe0d13fcb79004e5",
      "4275e87880584d6db1c42adc8c0a7012",
      "29c84aab5ea84c349a2a298cf176fa65",
      "793b76f033784dc6bae8769e311b1835",
      "94beb7c154704926a0ebdf58e95deb21",
      "4f4f9bc710554de5a30050f863d951b7",
      "10dddce7e3b34e279fabb7544fa374ca",
      "209f41f866564d4496d08411473085f4",
      "34b150e48a1449aba96cf2d90e8c1e9a",
      "5d78be8e368b4184ad0a5a48ce11b4cf",
      "da9d3a500b44457cbd77918bb1c3df23",
      "2f633a2872b048b39511b2a61921a473",
      "8d58ca6604004fe28c775ad6cbce13f6",
      "7679e7bdd09d4b09b03c374ce8c4a987",
      "1c69245a86584a73a11c0b97ea179414",
      "1ecb290955814bd78cb685f29147f665",
      "01bee5bcc1e84024bfd76a3a454d8ac5",
      "a454b30fe8354186ad84207f0cea6d3e",
      "049f7e2354054e0ebcea23e321a60e5e",
      "08dee1c2c1644bbaa9468df04b7b8991",
      "ff0b47c0f3124a9a844e15ada9d49c8b",
      "15123f023e5b4919854414c4a2491a63",
      "0cf77da9ce5f4e039411a5893854aa00"
     ]
    },
    "id": "Ye_5VWHex1R5",
    "outputId": "816a4017-b0ad-4c9a-d41d-8186eb2c5ecd"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Replace with your actual OpenAI API key\n",
    "api_key = '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'\n",
    "\n",
    "# Initialize the OpenAI API client\n",
    "openai.api_key = api_key\n",
    "\n",
    "# Load the Spider dataset\n",
    "data = load_dataset(\"spider\")\n",
    "\n",
    "em_count = 0\n",
    "count = 0\n",
    "# Iterate through the dataset\n",
    "for example in data['validation']:  # You can use 'train' or 'test' as well\n",
    "    count+=1\n",
    "    if count>200:\n",
    "      break\n",
    "    question = example['question']\n",
    "    ground_truth_query = example['query']\n",
    "\n",
    "    # Generate SQL query using the OpenAI GPT API\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt= \"What is the sql code for this query\" + question,\n",
    "        max_tokens=50,\n",
    "        api_key=api_key\n",
    "    )\n",
    "    generated_query = response.choices[0].text.strip()\n",
    "\n",
    "    # Check EM (Exact Match)\n",
    "    if generated_query.lower() == ground_truth_query.lower():\n",
    "        em_count += 1\n",
    "\n",
    "# Calculate EM percentage\n",
    "total_examples = len(data['validation'])  # You can use 'train' or 'test' as well\n",
    "em_percentage = (em_count / 200) * 100\n",
    "\n",
    "print(f\"Exact Match (EM) Percentage: {em_percentage}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GzR0RgheylOi",
    "outputId": "06632115-2801-4bfa-a29f-2887c73f5c1b"
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "id": "_7i98PHAJhG1",
    "outputId": "15540669-0342-41e5-e1f2-f04bd0b190e7"
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import json\n",
    "import sqlite3\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "\n",
    "def execute_query(database_path, query):\n",
    "    \"\"\" Execute a query on the specified SQLite database and return results. \"\"\"\n",
    "    conn = sqlite3.connect(database_path)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        results = cursor.fetchall()\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing query: {e}\")\n",
    "        results = None\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "    return results\n",
    "\n",
    "def load_spider_dataset_and_evaluate_accuracy(db_path):\n",
    "    \"\"\" Load Spider dataset and evaluate execution accuracy. \"\"\"\n",
    "    # Load validation dataset\n",
    "    data = load_dataset(\"spider\")\n",
    "\n",
    "    exec_acc_count = 0\n",
    "    count = 0\n",
    "\n",
    "    for example in data:\n",
    "        count += 1\n",
    "        if count > 200:\n",
    "            break\n",
    "\n",
    "        db_id = example['db_id']\n",
    "        database_file = f\"{db_path}/{db_id}.sqlite\"\n",
    "        question = example['question']\n",
    "        ground_truth_query = example['query']\n",
    "        generated_query = generate_query(question)  # Replace this with your query generation method\n",
    "\n",
    "        # Execute and compare queries\n",
    "        gt_results = execute_query(database_file, ground_truth_query)\n",
    "        gen_results = execute_query(database_file, generated_query)\n",
    "\n",
    "        if gt_results is not None and gen_results is not None and gt_results == gen_results:\n",
    "            exec_acc_count += 1\n",
    "\n",
    "    # Calculate execution accuracy\n",
    "    exec_acc_percentage = (exec_acc_count / count) * 100\n",
    "    return exec_acc_percentage\n",
    "\n",
    "# Paths to the dataset and database files\n",
    "# data_path = 'path/to/spider/validation/data.json'  # Update this path\n",
    "db_path = 'database'  # Update this path\n",
    "\n",
    "# Evaluate execution accuracy\n",
    "# accuracy = load_spider_dataset_and_evaluate_accuracy(data_path, db_path)\n",
    "# print(f\"Execution Accuracy: {accuracy}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "9cf2jeYWKLEL"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9155e86d75034ffcbf628993374c8084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import openai\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import json\n",
    "\n",
    "model_name = \"results_modified_schema/checkpoint-26250\"  # Replace with the path to your fine-tuned model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, cache_dir ='.')\n",
    "\n",
    "\n",
    "# Load your tables.json data\n",
    "with open('tables.json', 'r') as file:\n",
    "    tables = json.load(file)\n",
    "\n",
    "def generate_query(question, db_id):\n",
    "    \"\"\"\n",
    "    Generate an SQL query from a natural language question using the fine-tuned Llama model.\n",
    "\n",
    "    Parameters:\n",
    "    question (str): A natural language question.\n",
    "    db_id (str): Database identifier to fetch the schema.\n",
    "\n",
    "    Returns:\n",
    "    str: The generated SQL query.\n",
    "    \"\"\"\n",
    "    schema_info = next((item for item in tables if item.get('db_id') == db_id), None)\n",
    "    try:\n",
    "        # Prepare the prompt\n",
    "        prompt = f\"Write an SQL code for this query: {question}. QUERY: \"\n",
    "        \n",
    "        # Encode and generate the response\n",
    "        input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "        outputs = model.generate(input_ids, max_length=64, num_return_sequences=1)\n",
    "        generated_query = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "\n",
    "        return generated_query\n",
    "    except Exception as e:\n",
    "        print(f\"Error in query generation: {e}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8-hN4KGyLh2f",
    "outputId": "8494a979-05e9-45d1-d289-e2c4179ad0f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "db_file database/company_office/company_office.sqlite\n",
      "db_file database/storm_record/storm_record.sqlite\n",
      "db_file database/scholar/scholar.sqlite\n",
      "db_file database/train_station/train_station.sqlite\n",
      "db_file database/store_product/store_product.sqlite\n",
      "db_file database/flight_1/flight_1.sqlite\n",
      "db_file database/world_1/world_1.sqlite\n",
      "db_file database/local_govt_and_lot/local_govt_and_lot.sqlite\n",
      "db_file database/college_1/college_1.sqlite\n",
      "db_file database/local_govt_in_alabama/local_govt_in_alabama.sqlite\n",
      "db_file database/insurance_fnol/insurance_fnol.sqlite\n",
      "db_file database/music_1/music_1.sqlite\n",
      "db_file database/insurance_and_eClaims/insurance_and_eClaims.sqlite\n",
      "db_file database/network_1/network_1.sqlite\n",
      "db_file database/soccer_1/soccer_1.sqlite\n",
      "db_file database/movie_1/movie_1.sqlite\n",
      "db_file database/architecture/architecture.sqlite\n",
      "db_file database/tracking_grants_for_research/tracking_grants_for_research.sqlite\n",
      "db_file database/race_track/race_track.sqlite\n",
      "db_file database/entertainment_awards/entertainment_awards.sqlite\n",
      "db_file database/machine_repair/machine_repair.sqlite\n",
      "db_file database/behavior_monitoring/behavior_monitoring.sqlite\n",
      "db_file database/browser_web/browser_web.sqlite\n",
      "db_file database/voter_1/voter_1.sqlite\n",
      "db_file database/department_management/department_management.sqlite\n",
      "db_file database/gas_company/gas_company.sqlite\n",
      "db_file database/customers_and_products_contacts/customers_and_products_contacts.sqlite\n",
      "db_file database/tvshow/tvshow.sqlite\n",
      "db_file database/epinions_1/epinions_1.sqlite\n",
      "db_file database/local_govt_mdm/local_govt_mdm.sqlite\n",
      "db_file database/soccer_2/soccer_2.sqlite\n",
      "db_file database/mountain_photos/mountain_photos.sqlite\n",
      "db_file database/activity_1/activity_1.sqlite\n",
      "db_file database/perpetrator/perpetrator.sqlite\n",
      "db_file database/party_people/party_people.sqlite\n",
      "db_file database/pets_1/pets_1.sqlite\n",
      "db_file database/climbing/climbing.sqlite\n",
      "db_file database/tracking_orders/tracking_orders.sqlite\n",
      "db_file database/dorm_1/dorm_1.sqlite\n",
      "db_file database/game_1/game_1.sqlite\n",
      "db_file database/chinook_1/chinook_1.sqlite\n",
      "db_file database/film_rank/film_rank.sqlite\n",
      "db_file database/medicine_enzyme_interaction/medicine_enzyme_interaction.sqlite\n",
      "db_file database/cre_Docs_and_Epenses/cre_Docs_and_Epenses.sqlite\n",
      "db_file database/journal_committee/journal_committee.sqlite\n",
      "db_file database/party_host/party_host.sqlite\n",
      "db_file database/pilot_record/pilot_record.sqlite\n",
      "db_file database/singer/singer.sqlite\n",
      "db_file database/tracking_software_problems/tracking_software_problems.sqlite\n",
      "db_file database/musical/musical.sqlite\n",
      "db_file database/student_assessment/student_assessment.sqlite\n",
      "db_file database/university_basketball/university_basketball.sqlite\n",
      "db_file database/imdb/imdb.sqlite\n",
      "db_file database/cre_Theme_park/cre_Theme_park.sqlite\n",
      "db_file database/performance_attendance/performance_attendance.sqlite\n",
      "db_file database/school_bus/school_bus.sqlite\n",
      "db_file database/customers_and_addresses/customers_and_addresses.sqlite\n",
      "db_file database/geo/geo.sqlite\n",
      "db_file database/bike_1/bike_1.sqlite\n",
      "db_file database/allergy_1/allergy_1.sqlite\n",
      "db_file database/apartment_rentals/apartment_rentals.sqlite\n",
      "db_file database/e_government/e_government.sqlite\n",
      "db_file database/culture_company/culture_company.sqlite\n",
      "db_file database/customers_and_invoices/customers_and_invoices.sqlite\n",
      "db_file database/cre_Doc_Template_Mgt/cre_Doc_Template_Mgt.sqlite\n",
      "db_file database/shop_membership/shop_membership.sqlite\n",
      "db_file database/formula_1/formula_1.sqlite\n",
      "db_file database/loan_1/loan_1.sqlite\n",
      "db_file database/protein_institute/protein_institute.sqlite\n",
      "db_file database/voter_2/voter_2.sqlite\n",
      "db_file database/aircraft/aircraft.sqlite\n",
      "db_file database/assets_maintenance/assets_maintenance.sqlite\n",
      "db_file database/debate/debate.sqlite\n",
      "db_file database/product_catalog/product_catalog.sqlite\n",
      "db_file database/workshop_paper/workshop_paper.sqlite\n",
      "db_file database/inn_1/inn_1.sqlite\n",
      "db_file database/cre_Drama_Workshop_Groups/cre_Drama_Workshop_Groups.sqlite\n",
      "db_file database/news_report/news_report.sqlite\n",
      "db_file database/manufactory_1/manufactory_1.sqlite\n",
      "db_file database/city_record/city_record.sqlite\n",
      "db_file database/restaurants/restaurants.sqlite\n",
      "db_file database/document_management/document_management.sqlite\n",
      "db_file database/driving_school/driving_school.sqlite\n",
      "db_file database/college_3/college_3.sqlite\n",
      "db_file database/company_1/company_1.sqlite\n",
      "db_file database/customer_deliveries/customer_deliveries.sqlite\n",
      "db_file database/program_share/program_share.sqlite\n",
      "db_file database/flight_2/flight_2.sqlite\n",
      "db_file database/music_2/music_2.sqlite\n",
      "db_file database/club_1/club_1.sqlite\n",
      "db_file database/wta_1/wta_1.sqlite\n",
      "db_file database/museum_visit/museum_visit.sqlite\n",
      "db_file database/county_public_safety/county_public_safety.sqlite\n",
      "db_file database/orchestra/orchestra.sqlite\n",
      "db_file database/real_estate_properties/real_estate_properties.sqlite\n",
      "db_file database/railway/railway.sqlite\n",
      "db_file database/csu_1/csu_1.sqlite\n",
      "db_file database/swimming/swimming.sqlite\n",
      "db_file database/scientist_1/scientist_1.sqlite\n",
      "db_file database/wine_1/wine_1.sqlite\n",
      "db_file database/products_gen_characteristics/products_gen_characteristics.sqlite\n",
      "db_file database/company_employee/company_employee.sqlite\n",
      "db_file database/election_representative/election_representative.sqlite\n",
      "db_file database/school_player/school_player.sqlite\n",
      "db_file database/concert_singer/concert_singer.sqlite\n",
      "db_file database/products_for_hire/products_for_hire.sqlite\n",
      "db_file database/roller_coaster/roller_coaster.sqlite\n",
      "db_file database/decoration_competition/decoration_competition.sqlite\n",
      "db_file database/baseball_1/baseball_1.sqlite\n",
      "db_file database/theme_gallery/theme_gallery.sqlite\n",
      "db_file database/cinema/cinema.sqlite\n",
      "db_file database/college_2/college_2.sqlite\n",
      "db_file database/candidate_poll/candidate_poll.sqlite\n",
      "db_file database/ship_1/ship_1.sqlite\n",
      "db_file database/hospital_1/hospital_1.sqlite\n",
      "db_file database/farm/farm.sqlite\n",
      "db_file database/network_2/network_2.sqlite\n",
      "db_file database/academic/academic.sqlite\n",
      "db_file database/manufacturer/manufacturer.sqlite\n",
      "db_file database/device/device.sqlite\n",
      "db_file database/book_2/book_2.sqlite\n",
      "db_file database/icfp_1/icfp_1.sqlite\n",
      "db_file database/battle_death/battle_death.sqlite\n",
      "db_file database/poker_player/poker_player.sqlite\n",
      "db_file database/sports_competition/sports_competition.sqlite\n",
      "db_file database/insurance_policies/insurance_policies.sqlite\n",
      "db_file database/twitter_1/twitter_1.sqlite\n",
      "db_file database/employee_hire_evaluation/employee_hire_evaluation.sqlite\n",
      "db_file database/solvency_ii/solvency_ii.sqlite\n",
      "db_file database/body_builder/body_builder.sqlite\n",
      "db_file database/cre_Doc_Tracking_DB/cre_Doc_Tracking_DB.sqlite\n",
      "db_file database/music_4/music_4.sqlite\n",
      "db_file database/tracking_share_transactions/tracking_share_transactions.sqlite\n",
      "db_file database/riding_club/riding_club.sqlite\n",
      "db_file database/customers_campaigns_ecommerce/customers_campaigns_ecommerce.sqlite\n",
      "db_file database/restaurant_1/restaurant_1.sqlite\n",
      "db_file database/game_injury/game_injury.sqlite\n",
      "db_file database/entrepreneur/entrepreneur.sqlite\n",
      "db_file database/phone_1/phone_1.sqlite\n",
      "db_file database/small_bank_1/small_bank_1.sqlite\n",
      "db_file database/yelp/yelp.sqlite\n",
      "db_file database/flight_company/flight_company.sqlite\n",
      "db_file database/ship_mission/ship_mission.sqlite\n",
      "db_file database/student_transcripts_tracking/student_transcripts_tracking.sqlite\n",
      "db_file database/customer_complaints/customer_complaints.sqlite\n",
      "db_file database/station_weather/station_weather.sqlite\n",
      "db_file database/sakila_1/sakila_1.sqlite\n",
      "db_file database/customers_card_transactions/customers_card_transactions.sqlite\n",
      "db_file database/student_1/student_1.sqlite\n",
      "db_file database/department_store/department_store.sqlite\n",
      "db_file database/wrestler/wrestler.sqlite\n",
      "db_file database/dog_kennels/dog_kennels.sqlite\n",
      "db_file database/hr_1/hr_1.sqlite\n",
      "db_file database/phone_market/phone_market.sqlite\n",
      "db_file database/match_season/match_season.sqlite\n",
      "db_file database/store_1/store_1.sqlite\n",
      "db_file database/course_teach/course_teach.sqlite\n",
      "db_file database/e_learning/e_learning.sqlite\n",
      "db_file database/election/election.sqlite\n",
      "db_file database/wedding/wedding.sqlite\n",
      "db_file database/coffee_shop/coffee_shop.sqlite\n",
      "db_file database/car_1/car_1.sqlite\n",
      "db_file database/school_finance/school_finance.sqlite\n",
      "db_file database/flight_4/flight_4.sqlite\n",
      "db_file database/gymnast/gymnast.sqlite\n",
      "db_file database/cre_Doc_Control_Systems/cre_Doc_Control_Systems.sqlite\n",
      "Start\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATED_QUERY Write an SQL code for this query: How many singers do we have?. QUERY:  from singer_detail where detail like 'Sing%' order by detail; EXPlain the result in detail string. And also tell me in which table the result is stored. Thank you.\n",
      "I need to\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR near \"Write\": syntax error\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR near \"Write\": syntax error\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "Start\n",
      "GENERATED_QUERY Write an SQL code for this query: What is the total number of singers?. QUERY: 1. SELECT * FROM singers. 2. ORDER BY id. 3. LIMIT 5. EXPLAIN. And the result is: 1. 4. 5.\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR near \"Write\": syntax error\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR near \"Write\": syntax error\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "ERROR no such table: singer\n",
      "Start\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 62\u001b[0m\n\u001b[1;32m     59\u001b[0m ground_truth_query \u001b[38;5;241m=\u001b[39m example[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Assume the OpenAI API has been called and we have a generated_query\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m generated_query \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb_id\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# This should be the generated query from the API\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGENERATED_QUERY\u001b[39m\u001b[38;5;124m\"\u001b[39m, generated_query)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Check EM (Exact Match)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[12], line 32\u001b[0m, in \u001b[0;36mgenerate_query\u001b[0;34m(question, db_id)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Encode and generate the response\u001b[39;00m\n\u001b[1;32m     31\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mencode(prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m generated_query \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m generated_query\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1719\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1711\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1712\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1713\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1714\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1715\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1716\u001b[0m     )\n\u001b[1;32m   1718\u001b[0m     \u001b[38;5;66;03m# 13. run sample\u001b[39;00m\n\u001b[0;32m-> 1719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1720\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1721\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1722\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1723\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1724\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1725\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1726\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1727\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1728\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1729\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1730\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1731\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1733\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH:\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   1736\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1737\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1742\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   1743\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/generation/utils.py:2801\u001b[0m, in \u001b[0;36mGenerationMixin.sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2798\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2800\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2801\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2802\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2804\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2805\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2806\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2809\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:1034\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1031\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1034\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1036\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1037\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1038\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1043\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1046\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:922\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    912\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    913\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    914\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    919\u001b[0m         use_cache,\n\u001b[1;32m    920\u001b[0m     )\n\u001b[1;32m    921\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 922\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    931\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:672\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    669\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    671\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 672\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    683\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:368\u001b[0m, in \u001b[0;36mLlamaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    366\u001b[0m     query_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_proj(hidden_states)\n\u001b[1;32m    367\u001b[0m     key_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_proj(hidden_states)\n\u001b[0;32m--> 368\u001b[0m     value_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m query_states \u001b[38;5;241m=\u001b[39m query_states\u001b[38;5;241m.\u001b[39mview(bsz, q_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    371\u001b[0m key_states \u001b[38;5;241m=\u001b[39m key_states\u001b[38;5;241m.\u001b[39mview(bsz, q_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_key_value_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/peft/tuners/lora/layer.py:374\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    372\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_layer(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 374\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m active_adapter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactive_adapters:\n\u001b[1;32m    376\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m active_adapter \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlora_A\u001b[38;5;241m.\u001b[39mkeys():\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Function to open connections to all .sqlite files\n",
    "def open_sqlite_connections(sqlite_files):\n",
    "    connections = {}\n",
    "    for db_file in sqlite_files:\n",
    "        try:\n",
    "            conn = sqlite3.connect(db_file)\n",
    "            connections[db_file] = conn\n",
    "            print(\"db_file\", db_file)\n",
    "        except sqlite3.Error as e:\n",
    "            print(f\"Error connecting to database {db_file}: {e}\")\n",
    "    return connections\n",
    "\n",
    "def find_sqlite_files(directory):\n",
    "    sqlite_files = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.sqlite'):\n",
    "                sqlite_files.append(os.path.join(root, file))\n",
    "    return sqlite_files\n",
    "\n",
    "def eval_exec_match(ground_truth_query, generated_query, conn):\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Execute ground truth query\n",
    "        cursor.execute(ground_truth_query)\n",
    "        ground_truth_result = cursor.fetchall()\n",
    "\n",
    "        # Execute generated query\n",
    "        cursor.execute(generated_query)\n",
    "        generated_result = cursor.fetchall()\n",
    "\n",
    "        # Compare results\n",
    "        print(\"GT\", ground_truth_result)\n",
    "        print(\"GENERATED\", generated_result)\n",
    "        return ground_truth_result == generated_result\n",
    "    except sqlite3.Error as e:\n",
    "        print(\"ERROR\", e)\n",
    "        return False\n",
    "\n",
    "\n",
    "# Load the Spider dataset\n",
    "data = load_dataset(\"spider\")\n",
    "\n",
    "em_count = 0\n",
    "exec_count = 0\n",
    "count = 0\n",
    "\n",
    "# Assuming the SQLite files are located in a 'database' directory within 'spider'\n",
    "sqlite_files = find_sqlite_files('database')\n",
    "connections = open_sqlite_connections(sqlite_files)\n",
    "\n",
    "# Iterate through the dataset\n",
    "for example in data['validation']:\n",
    "    print(\"Start\")\n",
    "    count += 1\n",
    "    question = example['question']\n",
    "    db_id = example['db_id']\n",
    "    ground_truth_query = example['query']\n",
    "\n",
    "    # Assume the OpenAI API has been called and we have a generated_query\n",
    "    generated_query = generate_query(question, db_id)  # This should be the generated query from the API\n",
    "    print(\"GENERATED_QUERY\", generated_query)\n",
    "    # Check EM (Exact Match)\n",
    "    if generated_query.lower() == ground_truth_query.lower():\n",
    "        em_count += 1\n",
    "        print(\"HERe\")\n",
    "\n",
    "    # Check Execution Accuracy\n",
    "    for db_file, conn in connections.items():\n",
    "        if eval_exec_match(ground_truth_query, generated_query, conn):\n",
    "            exec_count += 1\n",
    "            print(\"here\")\n",
    "            # Stop checking once a match is found for this example\n",
    "\n",
    "# Close all database connections\n",
    "for conn in connections.values():\n",
    "    conn.close()\n",
    "\n",
    "# Calculate EM percentage\n",
    "em_percentage = (em_count / min(count, 200)) * 100\n",
    "exec_percentage = (exec_count / min(count, 200)) * 100\n",
    "\n",
    "print(f\"Exact Match (EM) Percentage: {em_percentage}%\")\n",
    "print(f\"Execution Match (Exec) Percentage: {exec_percentage}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d-bvAMAnZUEr",
    "outputId": "9a3e7f9c-6808-4e11-b1e3-a3d6aed645b0"
   },
   "outputs": [],
   "source": [
    "em_percentage = (em_count / count )* 100\n",
    "exec_percentage = (exec_count / count) * 100\n",
    "\n",
    "print(f\"Exact Match (EM) Percentage: {em_percentage}%\")\n",
    "print(f\"Execution Match (Exec) Percentage: {exec_percentage}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['singer', 'song']\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "def list_tables(sqlite_file):\n",
    "    conn = sqlite3.connect(sqlite_file)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = cursor.fetchall()\n",
    "    conn.close()\n",
    "    return [table[0] for table in tables]\n",
    "\n",
    "# Replace with the path to your SQLite file\n",
    "sqlite_file = 'database/singer/singer.sqlite'\n",
    "print(list_tables(sqlite_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'singer' LIKE %[s]% AND level > 5. ORDER BY level. LIMIT 5. Offset 0.\n",
      "Write an SQL code for this query: SELECT level from sing\n",
      "ERROR near \"'singer'\": syntax error\n",
      "SELECT ... FROM ... ORDER BY ..., but limit the number of results to 10. And, please, post the SQL code. Thanks.\n",
      "Ask the singers who has the highest height\n",
      "ERROR near \".\": syntax error\n",
      "SELECT * FROM singer where age < 25. ORDER BY age ASC. And the result is: age, country, sex.\n",
      "Write\n",
      "ERROR near \".\": syntax error\n",
      "1. that has produced a song in English, and 2. whose nationality is not \"China\".. Order the results by age in desc\n",
      "ERROR near \"1.\": syntax error\n",
      "1. SELECT 'France' FROM 'Singers' WHERE 'France' is a country. 2. SELECT 'France' FROM 'Singers' ORDER BY\n",
      "ERROR near \"1.\": syntax error\n",
      "SELECT * FROM Singers WHERE nationality = 'France' ORDER BY age DESC.  And list the result in descending order of age. List the nationality and\n",
      "ERROR near \".\": syntax error\n",
      "SELECT * FROM  music  WHERE  market  =  'Japan'  AND  type  =  'LP'  ORDER  BY  year  ASC\n",
      "ERROR no such table: music\n",
      "1. SELECT \"Day\" from \"Records\" WHERE \"Records\" < \"Bang\" AND \"Bang\" > 1980\n",
      "ERROR near \"1.\": syntax error\n",
      "SELECT * FROM singer where country is not null ORDER BY singer country.country? And what is the country of the singers? List all of them. And also list\n",
      "ERROR near \"country\": syntax error\n",
      "country, singer age 20, and the country language. ORDER BY country. And please return the result set in the order of country, language, and singer age\n",
      "ERROR near \"country\": syntax error\n",
      "SELECT country from singers where age > 23. ORDER BY country. And please print the results in the order of country. Thanks.\n",
      "Write an SQL code for this query\n",
      "ERROR near \"And\": syntax error\n",
      "FROM singer WHERE country like 'Japan' or country like 'Korea' ORDER by country. RETURN country and singer name. ORDER by country. And please write the count of singers in\n",
      "ERROR near \"FROM\": syntax error\n",
      "SELECT * FROM songs ORDER BY  musician age DESC. And list the result set in descending order by age. And print the result set in descending order by age. And print\n",
      "ERROR near \"age\": syntax error\n",
      "select * from song where artist age > 25. ORDER BY song rating. DATA TYPE: CHAR.\n",
      "Write the SQL code to list the first 5\n",
      "ERROR near \"age\": syntax error\n",
      "SELECT  *  FROM  stadiums  WHERE  city  == \"New York City\"  ORDER  by  city\n",
      "ERROR no such table: stadiums\n",
      "SELECT * FROM Stations. ORDER BY Station_Desc. And write the corresponding SQL code. CHALLENGE:\n",
      "ERROR near \"ORDER\": syntax error\n",
      "SELECT capacity, avg(seats), seas from stadiums where seats>10000;. ORDER BY seats descending and seating capacity descending;\n",
      "ERROR no such table: stadiums\n",
      "SELECT capacity, AvgCapacity from Stadiums;. EXPLAIN:  SELECT capacity, AvgCapacity from Stadiums;. ORDER BY capacity, Avg\n",
      "ERROR no such table: Stadiums\n",
      "SELECT name, capacity from stadiums ORDER BY capacity desc and name asc. ARN: 10000. NAME: Sydney Opera House. CAPAC\n",
      "ERROR near \"and\": syntax error\n",
      "select * from stadium where name like '%Arctic%'. ARGUMENT:  name. PRODUCE:  capacity. ORDER BY capacity ASC\n",
      "ERROR unrecognized token: \":\"\n",
      "select year from concerts.\n",
      "Write an SQL code for this query: how many tickets were sold for each concert? ORDER BY ticket by year\n",
      "ERROR near \"SQL\": syntax error\n",
      "SELECT concert.status, concert.venue from concert where date between 2014 and 2015. ORDER BY date. And what is\n",
      "ERROR near \"And\": syntax error\n",
      "SELECT  *  FROM  TicketTable WHERE  TicketTable.StartDate <= 2016-08-01 AND TicketTable\n",
      "ERROR incomplete input\n",
      "SELECT * FROM concerts.\n",
      "Write an SQL code for this query: SELECT * FROM concerts ORDER BY date. QUERY:  SELECT * FROM concerts.\n",
      "Write an\n",
      "ERROR near \"SQL\": syntax error\n",
      "SELECT * FROM concerts ORDER BY date_registered DESC. 1000000000000\n",
      "ERROR near \".\": syntax error\n",
      "SELECT name from stadium where capacity > 60000 And name contains 'Arise'. ORDER BY capacity. DESC\n",
      "ERROR near \"contains\": syntax error\n",
      "select year from concerts. The result is: 2012. Write the SQL code for this query: Which venue has most number of concerts? VIEW:  select ven\n",
      "ERROR near \"is\": syntax error\n",
      "1. That had more than 2000 concerts. ORDER BY year. SELECT year. Write the SQL code for this query: What are the top 3 countries by number of\n",
      "ERROR near \"1.\": syntax error\n",
      "select stadium name, city, state from stads without at least 1000 seats. ORDER BY city, state, seats, from highest to lowest. And also add city without at least\n",
      "ERROR near \"at\": syntax error\n",
      "SELECT stadium.name from stadium where stadium.name != 'None' and concert.name is null. ORDER BY stadium.name asc. CONTACT US if\n",
      "ERROR near \".\": syntax error\n",
      "SELECT country, age from singer where id not in (1,2,3,4,5,6,7,8,9,1\n",
      "ERROR incomplete input\n",
      "1. SELECT name FROM stadium WHERE name NOT LIKE 'Arena%' 2. SELECT name FROM stadium WHERE name LIKE 'Aren\n",
      "ERROR near \"1.\": syntax error\n",
      "14. That is, select all the stadiums that did not have a concert in 2014. ORDER BY their names\n",
      "ERROR near \"14.\": syntax error\n",
      "SELECT * FROM concerts ORDER BY theme, name; UNRESOLVED:  SELECT * FROM singers; SHOW THEMATIC\n",
      "ERROR no such table: concerts\n",
      "1. what is the theme of the concerts with a number of singers greater than 100? AND 2. what are the names of\n",
      "ERROR near \"1.\": syntax error\n",
      "SELECT * FROM concerts; SORT by name; ORDER by number of concerts ASC; UNSELECT all; Write the SQL code for this query: List the title of the work and\n",
      "ERROR no such table: concerts\n",
      "SELECT singer from concerts WHERE next concert is on or after 1986. ORDER BY singer\n",
      "ERROR near \"concert\": syntax error\n",
      "select * from concerts order by ticket price. CONSTRAIN:  not null. The result should be in the format: concert date, venue name, ticket\n",
      "ERROR near \"price\": syntax error\n",
      "4. SELECT * FROM singer. That said, some singers are better than others. The singer with the highest rating is: \"Ashley\n",
      "ERROR near \"4.\": syntax error\n",
      "SELECT 'Hey' like prefixes have been used in the songs of 2000s. ORDER BY year of the first\n",
      "ERROR near \"been\": syntax error\n",
      "SELECT * FROM singer WHERE song in ( 'Hey', 'Don't' ) ORDER BY best score;\n",
      "ERROR near \"t\": syntax error\n",
      "1. SELECT name, location from stadium where year between 2014 and\n",
      "ERROR near \"1.\": syntax error\n",
      "1. SELECT name, location from stadium where had_concert = TRUE; 2\n",
      "ERROR near \"1.\": syntax error\n",
      "SELECT * FROM concerts WHERE (venue capacity is greater than 6000) ORDER BY venue id, date, price, tickets price, tickets\n",
      "ERROR near \"capacity\": syntax error\n",
      "select concert.number of events from concerts where concert.number of events < 10000 order by concert.number of events asc And\n",
      "ERROR near \"events\": syntax error\n",
      "SELECT 1 FROM  Pet  WHERE  Pet 1 is a dog and its weight is greater than 10.  ORDER  by  Pet 1 '\n",
      "ERROR near \"1\": syntax error\n",
      "SELECT * FROM Pets WHERE PetWeight > 10; EXPLAIN:  . And list the result in descending order of PetWeight. List the result in the\n",
      "ERROR no such column: PetWeight\n",
      "SELECT  'Dog'  FROM  'Dog'  WHERE  'Dog'  = 1  AND  'Dog'  = 1  ORDER  BY  '\n",
      "ERROR unrecognized token: \"'\"\n",
      "1. The dog's name is Max. 2. The dog's birthday is in 2005. 3. The dog weighs between 10 and\n",
      "ERROR near \"1.\": syntax error\n",
      "SELECT MAX(Weight), PetType  FROM Pet  WHERE  Weight > 10  ORDER BY PetType, Weight  AND  PetType\n",
      "ERROR no such table: Pet\n",
      "SELECT  max(weight), type  FROM  pet  WHERE  type = 'Cat'  ORDER  by  weight  asc  and  type  desc  .  SORT\n",
      "ERROR near \"and\": syntax error\n",
      "select * from pets where type like 'Mouse' or 'Dog'  ORDER BY pet_id;  And the corresponding student id's.  And\n",
      "ERROR no such column: type\n",
      "select pets.number of students have an age greater than 20? .\n",
      "Write an SQL code for this query: select pets.number of\n",
      "ERROR near \"students\": syntax error\n",
      "SELECT * FROM pet WHERE sex p pet is a dog  And write the corresponding column name. And name of the table pet. And name of the student with\n",
      "ERROR near \"p\": syntax error\n",
      "'Dog' and 'Female' .  ORDER BY:  'Female' .  DESCENDING .  AND 'Dog' .  ASCENDING\n",
      "ERROR near \"'Dog'\": syntax error\n",
      "select * from Pet  where Pet.Type = 'Cat' or Pet.Type = 'Dog'  and Pet.OwnerId = 1.  ORDER BY Pet.Type DESC\n",
      "ERROR near \".\": syntax error\n",
      "SELECT COUNT(*) FROM Pet. Master the subject matter of all tests that have more than 2 points. If a candidate gets 1 point in any test, did he master the subject matter of that test\n",
      "ERROR near \"subject\": syntax error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT  first_name  FROM  student  WHERE  pet_type  LIKE  '%cat%'  OR  pet_type  LIKE  '%dog%'  ORDER  by\n",
      "ERROR incomplete input\n",
      "SELECT \"F\" from \"D\" where \"D\" is not null;. Write the name of every student who lives in a dorm with more than\n",
      "ERROR no such table: D\n",
      "SELECT  *  FROM  students  WHERE  pet  is  not  null  AND  salary  between   20000  and\n",
      "ERROR incomplete input\n",
      "select first name, last name from student where pet type is not null; EXPLAIN:  name(first) like 'Bernie' and\n",
      "ERROR near \"type\": syntax error\n",
      "SELECT major, age from student where pet is 'No'  ORDER BY age,  desc  .  And list the result set in the same order as the underlying table\n",
      "ERROR near \"And\": syntax error\n",
      "name, age, major from student. ORDER BY age, then name.\n",
      "Write an SQL code for this query: select name, age\n",
      "ERROR near \"name\": syntax error\n",
      "select * from students where (1=1 and 'Bob'=10011011) and (1=22222222) and\n",
      "ERROR incomplete input\n",
      "SELECT \"Student\" ( \"First\" , \"Johan\" , \"Norris\" , \"King\" , \"Ernesti\" , \"\n",
      "ERROR unrecognized token: \"\"\"\n",
      "SELECT  first_name, age  FROM  student  WHERE  dog  is  true  AND  cat  is  false\n",
      "ERROR no such column: first_name\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Function to find SQLite file based on db_id\n",
    "def find_sqlite_file(directory, db_id):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.sqlite') and db_id in file:\n",
    "                return os.path.join(root, file)\n",
    "    return None\n",
    "\n",
    "# Function to execute queries and compare results\n",
    "def eval_exec_match(ground_truth_query, generated_query, database_path):\n",
    "    try:\n",
    "        conn = sqlite3.connect(database_path)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Execute and compare queries\n",
    "        cursor.execute(ground_truth_query)\n",
    "        ground_truth_result = cursor.fetchall()\n",
    "\n",
    "        cursor.execute(generated_query)\n",
    "        generated_result = cursor.fetchall()\n",
    "\n",
    "        conn.close()\n",
    "        return ground_truth_result == generated_result\n",
    "    except sqlite3.Error as e:\n",
    "        print(\"ERROR\", e)\n",
    "        return False\n",
    "\n",
    "# Load the Spider dataset\n",
    "data = load_dataset(\"spider\")\n",
    "\n",
    "em_count = 0\n",
    "exec_count = 0\n",
    "count = 0\n",
    "db_directory = 'database'  # Directory containing the SQLite files\n",
    "\n",
    "for example in data['validation']:\n",
    "    count += 1\n",
    "    if count > 200:  # Limit to first 200 examples for efficiency\n",
    "        break\n",
    "\n",
    "    question = example['question']\n",
    "    db_id = example['db_id']\n",
    "    ground_truth_query = example['query']\n",
    "\n",
    "    # Generate the SQL query using your model\n",
    "    generated_query = generate_query(question, db_id)\n",
    "    query_start = generated_query.find(\"QUERY:\") + len(\"QUERY:\")\n",
    "\n",
    "# Extract the query\n",
    "    extracted_query = generated_query[query_start:].strip()\n",
    "\n",
    "# Clean up the query if necessary (remove trailing periods, etc.)\n",
    "    cleaned_query = extracted_query.rstrip('.').strip()\n",
    "\n",
    "    print(cleaned_query)\n",
    "#     print(generated_query)\n",
    "\n",
    "    # Check for Exact Match\n",
    "    if generated_query.lower() == ground_truth_query.lower():\n",
    "        em_count += 1\n",
    "\n",
    "    # Check Execution Match\n",
    "    database_path = find_sqlite_file(db_directory, db_id)\n",
    "    if database_path and eval_exec_match(ground_truth_query, extracted_query, database_path):\n",
    "        print(\"yay\")\n",
    "        exec_count += 1\n",
    "\n",
    "# Calculate and print the percentages\n",
    "em_percentage = (em_count / min(count, 200)) * 100\n",
    "exec_percentage = (exec_count / min(count, 200)) * 100\n",
    "\n",
    "print(f\"Exact Match (EM) Percentage: {em_percentage}%\")\n",
    "print(f\"Execution Match (Exec) Percentage: {exec_percentage}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "000d51fc5c404daba188f58c86ce72a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "01bee5bcc1e84024bfd76a3a454d8ac5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "049f7e2354054e0ebcea23e321a60e5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "08dee1c2c1644bbaa9468df04b7b8991": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0cf77da9ce5f4e039411a5893854aa00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0edebfbe8f204097ab9dd6e2d311bc16": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4362d479c3044e7a9e496e03ac1bc9a5",
      "max": 99736136,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2f9a4afa9c9d479a93b06cff6eda09c6",
      "value": 99736136
     }
    },
    "10dddce7e3b34e279fabb7544fa374ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "15123f023e5b4919854414c4a2491a63": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c69245a86584a73a11c0b97ea179414": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_08dee1c2c1644bbaa9468df04b7b8991",
      "max": 1034,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ff0b47c0f3124a9a844e15ada9d49c8b",
      "value": 1034
     }
    },
    "1ecb290955814bd78cb685f29147f665": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_15123f023e5b4919854414c4a2491a63",
      "placeholder": "​",
      "style": "IPY_MODEL_0cf77da9ce5f4e039411a5893854aa00",
      "value": " 1034/1034 [00:00&lt;00:00, 3485.31 examples/s]"
     }
    },
    "209f41f866564d4496d08411473085f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "29c84aab5ea84c349a2a298cf176fa65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_10dddce7e3b34e279fabb7544fa374ca",
      "placeholder": "​",
      "style": "IPY_MODEL_209f41f866564d4496d08411473085f4",
      "value": "Generating train split: 100%"
     }
    },
    "2f633a2872b048b39511b2a61921a473": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2f9a4afa9c9d479a93b06cff6eda09c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "34b150e48a1449aba96cf2d90e8c1e9a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3918ba3379414eb3a90ffd0c017d44b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d3a47070203a4079a6e0100a391f6df0",
      "placeholder": "​",
      "style": "IPY_MODEL_e20f1a733c4e468cbe0d13fcb79004e5",
      "value": " 99.7M/99.7M [00:02&lt;00:00, 40.7MB/s]"
     }
    },
    "4275e87880584d6db1c42adc8c0a7012": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_29c84aab5ea84c349a2a298cf176fa65",
       "IPY_MODEL_793b76f033784dc6bae8769e311b1835",
       "IPY_MODEL_94beb7c154704926a0ebdf58e95deb21"
      ],
      "layout": "IPY_MODEL_4f4f9bc710554de5a30050f863d951b7"
     }
    },
    "4362d479c3044e7a9e496e03ac1bc9a5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f4f9bc710554de5a30050f863d951b7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5d78be8e368b4184ad0a5a48ce11b4cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "691f9668a10e4f3883f56f37f54e3a0b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7679e7bdd09d4b09b03c374ce8c4a987": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a454b30fe8354186ad84207f0cea6d3e",
      "placeholder": "​",
      "style": "IPY_MODEL_049f7e2354054e0ebcea23e321a60e5e",
      "value": "Generating validation split: 100%"
     }
    },
    "793b76f033784dc6bae8769e311b1835": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_34b150e48a1449aba96cf2d90e8c1e9a",
      "max": 7000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5d78be8e368b4184ad0a5a48ce11b4cf",
      "value": 7000
     }
    },
    "8d58ca6604004fe28c775ad6cbce13f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7679e7bdd09d4b09b03c374ce8c4a987",
       "IPY_MODEL_1c69245a86584a73a11c0b97ea179414",
       "IPY_MODEL_1ecb290955814bd78cb685f29147f665"
      ],
      "layout": "IPY_MODEL_01bee5bcc1e84024bfd76a3a454d8ac5"
     }
    },
    "94beb7c154704926a0ebdf58e95deb21": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_da9d3a500b44457cbd77918bb1c3df23",
      "placeholder": "​",
      "style": "IPY_MODEL_2f633a2872b048b39511b2a61921a473",
      "value": " 7000/7000 [00:02&lt;00:00, 4377.04 examples/s]"
     }
    },
    "a454b30fe8354186ad84207f0cea6d3e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bf2e8347ab534e4c8194f8ccf55ec6a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7ff01223950457f8286c36374a89cd2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f6118099e4914a978c79ec9f6755d372",
       "IPY_MODEL_0edebfbe8f204097ab9dd6e2d311bc16",
       "IPY_MODEL_3918ba3379414eb3a90ffd0c017d44b5"
      ],
      "layout": "IPY_MODEL_bf2e8347ab534e4c8194f8ccf55ec6a2"
     }
    },
    "d3a47070203a4079a6e0100a391f6df0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "da9d3a500b44457cbd77918bb1c3df23": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e20f1a733c4e468cbe0d13fcb79004e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f6118099e4914a978c79ec9f6755d372": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_691f9668a10e4f3883f56f37f54e3a0b",
      "placeholder": "​",
      "style": "IPY_MODEL_000d51fc5c404daba188f58c86ce72a0",
      "value": "Downloading data: 100%"
     }
    },
    "ff0b47c0f3124a9a844e15ada9d49c8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
